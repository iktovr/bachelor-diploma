\section{РАЗРЕЖЕННАЯ ИДЕНТИФИКАЦИЯ НЕЛИНЕЙНЫХ ДИНАМИЧЕСКИХ СИСТЕМ}

\subsection{Теоретическое описание}

\subsubsection{Структурный анализ нелинейных динамических систем}

Алгоритм, описываемый в данной работе, позволяет производить структурную идентификацию динамических систем \cite{sindy} вида:

\begin{equation}
\dot{\textsc{x}}(t) = f(\textsc{x}(t)),
\end{equation}

где вектор $\textsc{x}(t) = \left(x_1(t) \quad x_2(t) \quad \cdots \quad x_n(t)\right)^T \in \mathbb{R}^n$ описывает состояние системы в момент времени $t$;\par 
$f(\textsc{x}(t))$ --- нелинейная функция, описывающая поведение самой системы.

Ключевое наблюдение, лежащее в основе алгоритма, состоит в том, что большое число таких функций представляют из себя линейную комбинацию небольшого количества значимых членов, другими словами, они являются разреженными в пространстве возможных функций.

Для проведения структурной идентификации необходимо собрать множество измерений состояний системы $\textsc{x}(t)$ и соответствующие им значения производной. Эти измерения образуют две матрицы:

\begin{equation}
X =
\begin{pmatrix}
\textsc{x}^T(t_1) \\	
\textsc{x}^T(t_2) \\
\vdots \\	
\textsc{x}^T(t_m)	
\end{pmatrix}
=
\begin{pmatrix}
x_1(t_1) & x_2(t_1) & \cdots & x_n(t_1) \\
x_1(t_2) & x_2(t_2) & \cdots & x_n(t_2) \\
\vdots & \vdots & \ddots & \vdots \\
x_1(t_m) & x_2(t_m) & \cdots & x_n(t_m)
\end{pmatrix}
\end{equation}

\begin{equation}
\dot{X} = 
\begin{pmatrix}
\dot{\textsc{x}}^T(t_1) \\	
\dot{\textsc{x}}^T(t_2) \\
\vdots \\	
\dot{\textsc{x}}^T(t_m)	
\end{pmatrix}
=
\begin{pmatrix}
\dot{x_1}(t_1) & \dot{x_2}(t_1) & \cdots & \dot{x_n}(t_1) \\
\dot{x_1}(t_2) & \dot{x_2}(t_2) & \cdots & \dot{x_n}(t_2) \\
\vdots & \vdots & \ddots & \vdots \\
\dot{x_1}(t_m) & \dot{x_2}(t_m) & \cdots & \dot{x_n}(t_m)
\end{pmatrix}.
\end{equation}

В случае использования реальных экспериментальных данных (или синтезированных данных, которые призваны их заменить) значения производных будут неизвестны. В связи с этим возникает задача численного дифференцирования для получения данных значений. Такая задача может быть осложнена наличием шума в данных, что требует специальных алгоритмов дифференцирования, способных справиться с подобными затруднениями.

Следующим этапом составляется матрица признаков $\Theta(X)$, которая содержит нелинейные функции от столбцов $X$, предположительно содержащиеся в искомой системе. Например, она может состоять из константной функции, полиномов и тригонометрических функций:

\begin{equation}
\fontsize{13pt}{15pt}\selectfont
\renewcommand*{\arraystretch}{.5}
\Theta(X) = 
\begin{pmatrix}
| & | & | & | &  & | & | & | & | &  \\
1 & X & X^{P_2} & X^{P_3} & \cdots & \sin(X) & \cos(X) & \sin(2X) & \cos(2X) & \cdots \\
| & | & | & | &  & | & | & | & | & 
\end{pmatrix},
\end{equation}

где $X^{P_2}$, $X^{P_3}$ обозначают полиномы второй и третьей степени соответственно, например:

\begin{equation}
X^{P_2} = 
\begin{pmatrix}
x_1^2(t_1) & x_1(t_1) x_2(t_1) & \cdots & x_2^2(t_1) & x_2(t_1) x_3(t_1) & \cdots & x_n^2(t_1) \\ 
x_1^2(t_2) & x_1(t_2) x_2(t_2) & \cdots & x_2^2(t_2) & x_2(t_2) x_3(t_2) & \cdots & x_n^2(t_2) \\
\vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
x_1^2(t_m) & x_1(t_m) x_2(t_m) & \cdots & x_2^2(t_m) & x_2(t_m) x_3(t_m) & \cdots & x_n^2(t_m)
\end{pmatrix}.
\end{equation}

Теперь задача заключается в определении того, как именно надо скомбинировать столбцы матрицы признаков для получения векторов левых частей. Это есть ни что иное, как задача линейной регрессии, при этом, так как было сделано предположение, что искомая функция содержит небольшое число значимых членов, это конкретный подвид линейной регрессии --- разреженная регрессия --- при помощи которого можно получить разреженную матрицу коэффициентов $W$:

\begin{equation}
\dot{X} = \Theta(X) W.
\end{equation}

Столбцы матрицы $W$ определяют значимые члены правых частей каждого из уравнений системы и коэффициенты перед ними.

Таким образом, основными частями алгоритма являются численное дифференцирование и разреженная регрессия. Рассмотрим каждую из них подробно.

