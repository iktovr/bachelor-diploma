\subsubsection{Разреженная регрессия}

Задача линейной регрессии формулируется следующим образом. Имеется множество объектов и множество соответствующих им значений целевой переменной. Необходимо подобрать такие коэффициенты линейной комбинации признаков объектов, чтобы она лучше всего приближала значения целевой переменной в смысле некоторой функции потерь (обычно среднеквадратичного отклонения).

Таким образом, пусть имеется вектор значений целевой переменной $y = (y_i)_{i=1}^N \in \mathbb{R}_N$ и матрица признаков $X = (x_i)_{i=1}^N \in \mathbb{R}^{N \times D}$, $x_i \in \mathbb{R}^D$. Функция потерь имеет вид:

\begin{equation}
L(w) = \frac{1}{N} ||y - X w||^2_2 \longrightarrow \min_w,
\end{equation}

где $w$ --- искомые веса.

К решению такой задачи существует несколько подходов. Во-первых, можно получить аналитическое решение. Действительно, градиент функции потерь имеет вид:

\begin{equation}
\nabla L = \frac{2}{N} X^T (X w - y),
\end{equation}

а вторая производная:

\begin{equation}
L'' = \frac{2}{N} X^T X.
\end{equation}

Функция потерь квадратичная, следовательно имеет один экстремум, который является точкой минимума, так как матрица $\frac{2}{N} X^T X$ положительно определена (для любого $X$ с линейно независимыми столбцами). Таким образом, по необходимому условию экстремума, искомое $w$ получается как решение матричного уравнения:

\begin{align}
&X^T (X w - y) = 0 \\
&w = (X^T X)^{-1} X^T y.
\end{align}

Такое решение будет точным, однако, его вычисление включает в себя операцию обращения матрицы, что вычислительно дорого и может быть неприемлемо для большого объема данных. Более того, можно столкнутся с проблемой плохой обусловленности матрицы, что приведет к неустойчивости решения.

Поэтому другой способ заключается в решении задачи оптимизации методом градиентного спуска. Зная градиент функции потерь, само решение можно вычислить следующим итеративным процессом:

\begin{equation}
w_{k+1} = w_k - \eta \cdot \nabla L(w_k), 
\end{equation}

где $\eta$ --- скорость обучения --- контролирует величину шага в направлении антиградиента.

При помощи этого метода можно получать решение с некоторой точностью, но со значительно меньшим использованием вычислительных ресурсов.

Проблема описанного выше подхода (для любого метода решения) заключается в том, что на веса не накладывается никаких дополнительных ограничений. Это может привести, например, к их неограниченному росту при наличии коррелированных признаков, но, что более важно, каждому признаку будет приписан какой-то ненулевой вклад в целевую функцию. Этот вклад может быть очень маленьким, но его наличие не позволяет, например, просто откинуть наименее важные признаки, так как это потребует пересчета оставшихся весов и незначимые признаки могут возникнуть вновь.

Поэтому возникает потребность в алгоритмах разреженной регрессии, частью которых является отбор признаков и по результатам которых можно точно отделить признаки, не вносящие вклада в целевую функцию.

\paragraph{Lasso}

Одним из способов решения задачи разреженной регрессии является использование регуляризации --- штрафа на величину весов, который добавляется в функцию потерь. Наиболее распространены $L_1$ и $L_2$ регуляризации, в которых штраф имеет вид $L_1$ нормы $||w||_1 = \sum_i |w_i|$ и $L_2$ нормы $||w||_2 = \sqrt{\sum_i |w_i|^2}$ весов соответственно. В отличие от $L_2$ регуляризации, которая приводит только к уменьшению величины весов, $L_1$ регуляризация позволяет обнулять коэффициенты при самых незначимых признаках. В результате получается алгоритм Lasso --- Least absolute shrinkage and selection operator \cite{lasso}.

Вместе с добавленным штрафом, функция потерь выглядит следующим образом:

\begin{equation}
L(w) = \frac{1}{N} ||y - X w||^2_2 + \alpha ||w||_1,
\end{equation}

где $\alpha$ --- коэффициент регуляризации.

Технически, $L_1$ норма недифференцируема. Однако недифференцируема она только в одной точке (в нуле). Применительно к машинному обучению, можно считать, что вероятность встречи точного нуля крайне мала, и пренебречь этим. Тогда производная $L_1$ нормы --- это знаковая функция $\operatorname{sign}$, доопределенная в нуле (при помощи $1$ или $-1$). Таким образом градиент функции потерь:

\begin{equation}
\nabla L(w) = \frac{2}{N} X^T (X w - y) + \alpha \operatorname{sign}(w).
\end{equation}

Для получения решения используем метод градиентного спуска.

\paragraph{STLSQ}

Помимо классического Lasso авторы алгоритма идентификации предлагают собственный алгоритм разреженной регрессии STLSQ --- Sequential Thresholded Least-Squares \cite{sindy}.

Алгоритм заключается в следующем. Найдем решение задачи регрессии при помощи МНК --- метода наименьших квадратов --- любым способом. Такое решение не будет разреженным, но некоторые коэффициенты в нем будут меньше других. Обнулим коэффициенты, меньшие некоторого порогового значения $\alpha$. После этого снова найдем решение МНК, но уже для оставшихся коэффициентов, и опять обнулим коэффициенты. Эта процедура уточнения и отбора коэффициенты повторяется, пока все ненулевые не станут больше $\alpha$. Если произошло обнуление вообще всех коэффициентов, значит порог $\alpha$ выбран слишком большим и его надо уменьшить. Псевдокод алгоритма представлен на рисунке~\ref{alg:stlsq}.

\begin{figure}
\begin{minipage}{\linewidth}
\begin{algorithm}[H]
\SetAlgoVlined
\KwData{пороговое значение $\alpha$}
\KwIn{матрица признаков $X$, вектор целевой переменной $y$}
\KwOut{вектор весов $w$}

$w = \operatorname{solve}(X, y)$ \tcp*[l]{функция solve использует МНК}
\While{вектор $w$ изменяется}{
	$smallinds = |w| < \alpha$\;
	$w[smallinds] = 0$\;

	$biginds = \neg smallinds$\;
	$w[biginds] = \operatorname{solve}(X[biginds], y)$\;
}
\end{algorithm}
\end{minipage}
\caption{Псевдокод алгоритма STLSQ}
\label{alg:stlsq}
\end{figure}

Приведенные выше алгоритмы описаны для одной целевой функции, однако, они легко обобщаются на случай нескольких целевых функций. Lasso, как и другие алгоритмы, основанные на градиентном спуске, практически не требует изменений, так как градиент можно вычислять для любой размерности. В случае STLSQ алгоритм надо выполнять отдельно для каждого вектора целевых функций и весов.